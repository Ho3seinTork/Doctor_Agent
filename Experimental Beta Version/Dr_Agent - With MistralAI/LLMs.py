import os
import json
from dotenv import load_dotenv
import requests
import time
from typing import Tuple
import backoff
import urllib3

# Load environment variables securely to decouple configuration from code.
# This aids in maintaining environment-specific settings and supports the twelve-factor app methodology.
load_dotenv()
MISTRAL_API_KEY = os.getenv('MISTRAL_API_KEY')
MISTRAL_API_BASE = os.getenv('MISTRAL_API_BASE', 'https://api.mistral.ai')
MISTRAL_API_VERSION = "v1"
MISTRAL_API_ENDPOINT = f"{MISTRAL_API_BASE}/{MISTRAL_API_VERSION}/chat/completions"

# Configure optional proxies if defined, ensuring flexible network routing and compliance with corporate security policies.
HTTP_PROXY = os.getenv('HTTP_PROXY')
HTTPS_PROXY = os.getenv('HTTPS_PROXY')

# Initialize a persistence-enabled session object to facilitate connection reuse and integrated retry policies.
# This aligns with efficient resource management and minimizes overhead in network calls.
session = requests.Session()
if HTTP_PROXY or HTTPS_PROXY:
    session.proxies = {
        'http': HTTP_PROXY,
        'https': HTTPS_PROXY
    }

# Define a retry strategy using urllib3 to handle transient HTTP errors robustly.
# This strategy ensures graceful degradation under load and mitigates issues from intermittent connectivity.
retry_strategy = urllib3.util.Retry(
    total=3,
    backoff_factor=1,
    status_forcelist=[429, 500, 502, 503, 504]
)
adapter = requests.adapters.HTTPAdapter(max_retries=retry_strategy)
session.mount("http://", adapter)
session.mount("https://", adapter)

# Establish a detailed system prompt to direct the AI's clinical responses.
# This design encourages consistency in diagnostic recommendations by aligning the model with domain-specific best practices.
SYSTEM_PROMPT = """Ø´Ù…Ø§ ÛŒÚ© Ù¾Ø²Ø´Ú© Ù…ØªØ®ØµØµ Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø¹Ù„Ø§Ø¦Ù… Ø¨ÛŒÙ…Ø§Ø±ØŒ ØªØ´Ø®ÛŒØµ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ùˆ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ø±Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯.
Ù„Ø·ÙØ§ Ù¾Ø§Ø³Ø® Ø®ÙˆØ¯ Ø±Ø§ Ø¯Ø± Ù‚Ø§Ù„Ø¨ Ø²ÛŒØ± Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯:

ğŸ“‹ ØªØ´Ø®ÛŒØµ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ:
[ØªØ´Ø®ÛŒØµ Ù‡Ø§ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø±Ø§ Ø¨Ù‡ ØªØ±ØªÛŒØ¨ Ø§ÙˆÙ„ÙˆÛŒØª Ø°Ú©Ø± Ú©Ù†ÛŒØ¯]
+ 5 ØªØ´Ø®ÛŒØµ  Ø¨ÛŒÙ…Ø§Ø±ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø­Ø§ØµÙ„ Ø§Ø² Ø¹Ù„Ø§Ø¦Ù… Ø¨Ø§Ù„Ø§

âš•ï¸ ØªÙˆØ¶ÛŒØ­Ø§Øª:
[ØªÙˆØ¶ÛŒØ­ Ù…Ø®ØªØµØ± Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø¯Ù„ÛŒÙ„ Ø§ÛŒÙ† ØªØ´Ø®ÛŒØµ Ù‡Ø§]
+ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¯Ø§Ø±Ùˆ Ù‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ù…Ø§Ù†

ğŸ’Š ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§:
[ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ùˆ Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ø§Ø­ØªÛŒØ§Ø·ÛŒ]
+ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ØªØºØ°ÛŒÙ‡  Ùˆ Ø³Ù„Ø§Ù…ØªÛŒ
+ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø±Ø§ÛŒ Ø·Ø¨ Ø³Ù†ØªÛŒ

âš ï¸ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§:
[Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ Ø¹Ù„Ø§Ø¦Ù… Ø®Ø·Ø±Ù†Ø§Ú© ÛŒØ§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù…Ø±Ø§Ø¬Ø¹Ù‡ ÙÙˆØ±ÛŒ Ø¨Ù‡ Ù¾Ø²Ø´Ú©]"""

# Apply the exponential backoff design pattern to manage transient failures.
# This decorator ensures that retry attempts are spaced exponentially, reducing the risk of overwhelming the API service.
@backoff.on_exception(
    backoff.expo,
    (requests.exceptions.RequestException, json.JSONDecodeError),
    max_tries=5,
    max_time=120
)
def make_api_request(headers: dict, data: dict, timeout: int = 90):
    """Perform an API call with integrated error handling and retry logic.
    
    This abstraction facilitates robust external integrations by capturing common I/O exceptions and providing
    insightful error messages that simplify downstream troubleshooting.
    """
    try:
        response = session.post(
            MISTRAL_API_ENDPOINT,
            headers=headers,
            json=data,
            timeout=(15, timeout)
        )
        response.raise_for_status()
        return response.json()
    except requests.exceptions.Timeout:
        # Indicates potential network latency or server-side slowness. Consider reviewing infrastructure if frequent.
        raise Exception("Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ø§ ØªØ§Ø®ÛŒØ± Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯ - Ù„Ø·ÙØ§Ù‹ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯")
    except requests.exceptions.ConnectionError:
        # Highlights possible connectivity issues; ensure network availability or proxy configurations.
        raise Exception("Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ - Ù„Ø·ÙØ§Ù‹ Ø§ØªØµØ§Ù„ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯")
    except requests.exceptions.HTTPError as e:
        # Handle specific HTTP errors to offer precise feedback and control application flow.
        if response.status_code == 401:
            raise Exception("Ú©Ù„ÛŒØ¯ API Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª") from e
        elif response.status_code == 429:
            raise Exception("Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ú†Ù†Ø¯ Ø¯Ù‚ÛŒÙ‚Ù‡ ØµØ¨Ø± Ú©Ù†ÛŒØ¯") from e
        elif response.status_code >= 500:
            raise Exception("Ø®Ø·Ø§ÛŒ Ø³Ø±ÙˆØ± Mistral AI") from e
        raise
    except Exception as e:
        # Fallback for all unexpected exceptions; log details may be required for post-mortem debugging.
        raise Exception(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {str(e)}")

def call_language_model(prompt: str, max_retries: int = 3, retry_delay: int = 2) -> str:
    """Engage the Mistral AI API with meticulous error management and retry schemes.
    
    This function encapsulates the full interaction lifecycle with the external API, including fallback logic that
    maintains service continuity when facing repeated transient failures.
    """
    
    if not MISTRAL_API_KEY:
        return "Ø®Ø·Ø§: Ú©Ù„ÛŒØ¯ API ÛŒØ§ÙØª Ù†Ø´Ø¯"

    headers = {
        "Authorization": f"Bearer {MISTRAL_API_KEY}",
        "Content-Type": "application/json",
        "Accept": "application/json"
    }
    
    data = {
        "model": "mistral-medium",  # Align with defined model archetypes for consistent AI performance.
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7,
        "max_tokens": 2000,
        "stream": False
    }

    # Predefine a fallback response to ensure system responsiveness even when the external service fails repeatedly.
    fallback_response = """
ğŸ“‹ ØªØ´Ø®ÛŒØµ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ:
Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø§Ø®ØªÙ„Ø§Ù„ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ø³Ø±ÙˆØ±ØŒ Ø§Ù…Ú©Ø§Ù† ØªØ´Ø®ÛŒØµ Ø¯Ù‚ÛŒÙ‚ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.

âš•ï¸ ØªÙˆØ¶ÛŒØ­Ø§Øª:
Ù„Ø·ÙØ§Ù‹ Ú†Ù†Ø¯ Ø¯Ù‚ÛŒÙ‚Ù‡ Ø¯ÛŒÚ¯Ø± Ù…Ø¬Ø¯Ø¯Ø§Ù‹ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.

ğŸ’Š ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§:
Ø¯Ø± ØµÙˆØ±Øª Ø´Ø¯ÛŒØ¯ Ø¨ÙˆØ¯Ù† Ø¹Ù„Ø§Ø¦Ù…ØŒ Ø¨Ù‡ Ù¾Ø²Ø´Ú© Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯.

âš ï¸ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§:
Ø§ÛŒÙ† Ù¾Ø§Ø³Ø® Ù…ÙˆÙ‚Øª Ø§Ø³Øª Ùˆ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ù…Ø´Ø§ÙˆØ±Ù‡ Ù¾Ø²Ø´Ú©ÛŒ Ù†ÛŒØ³Øª.
"""

    for attempt in range(max_retries):
        try:
            print(f"Making API request attempt {attempt + 1}")  # Log attempt to support traceability.
            response_data = make_api_request(headers, data)
            
            if 'choices' in response_data:
                content = response_data['choices'][0]['message']['content'].strip()
                if content:
                    return content
                
            print(f"Invalid response format on attempt {attempt + 1}")  # Alert on schema mismatch and potential API changes.
            if attempt < max_retries - 1:
                time.sleep(retry_delay * (attempt + 1))  # Exponential delay integration enhances overall system stability.
                continue
                
        except Exception as e:
            print(f"Error on attempt {attempt + 1}: {str(e)}")  # Error logging for operational diagnostics.
            if attempt < max_retries - 1:
                time.sleep(retry_delay * (attempt + 1))
                continue
            elif "Invalid API key" in str(e):
                return "Ø®Ø·Ø§: Ú©Ù„ÛŒØ¯ API Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª"
            elif "Rate limit exceeded" in str(e):
                return "Ø®Ø·Ø§: Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ú†Ù†Ø¯ Ø¯Ù‚ÛŒÙ‚Ù‡ ØµØ¨Ø± Ú©Ù†ÛŒØ¯"
            elif "server error" in str(e):
                return "Ø®Ø·Ø§: Ø³Ø±ÙˆØ± Mistral AI Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª"
            
    # Return the predefined fallback response after all retry attempts have been exhausted.
    return fallback_response
